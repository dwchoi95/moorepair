{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.genetic import Fitness\n",
    "from src.utils import Database, DBKey, divide\n",
    "import math, json, os, glob\n",
    "\n",
    "\n",
    "problem_map = {\n",
    "    'ICL1701': '1',\n",
    "    'TRMAG': '2',\n",
    "    'MAXSCRAB': '3',\n",
    "    'LPAIR': '4',\n",
    "    'RUMBLING': '5',\n",
    "    'TREEROOT': '6',\n",
    "    'MINORPATH': '7'\n",
    "}\n",
    "fitness = Fitness()\n",
    "stars = {obj:{} for obj in fitness.objectives}\n",
    "dataset = 'data'\n",
    "experiments = glob.glob(f'{dataset}/**/experiment.json', recursive=True)\n",
    "for exp in experiments:\n",
    "    exp_db = Database(exp)\n",
    "    for data in exp_db.all():\n",
    "        problem = problem_map[data[DBKey.problem]]\n",
    "        approach = data[DBKey.approach]\n",
    "        for obj in fitness.objectives:\n",
    "            stars[obj].setdefault(problem, {})\n",
    "            stars[obj][problem][approach] = data[obj]\n",
    "\n",
    "stars.update({'minimal changes': stars['similarity']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_scores = {obj:{} for obj in fitness.objectives}\n",
    "for obj in fitness.objectives:\n",
    "    for problem in stars[obj]:\n",
    "        scores = stars[obj][problem]\n",
    "        for approach in scores:\n",
    "            overall_scores[obj].setdefault(approach, 0)\n",
    "            overall_scores[obj][approach] += scores[approach]\n",
    "\n",
    "overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "approach_map = {\n",
    "    'zero': 'zero-shot',\n",
    "    'random': 'few-shot(random)',\n",
    "    'optimal': 'few-shot(optimal)',\n",
    "}\n",
    "color_map = {\n",
    "    'zero': 'red',\n",
    "    'random': 'green',\n",
    "    'optimal': 'blue',\n",
    "}\n",
    "\n",
    "sorted_stars = sorted(stars['minimal changes'])\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=True, sharey=False)\n",
    "for ax, obj in zip(axes, fitness.objectives):\n",
    "    if obj == 'similarity':\n",
    "        obj = 'minimal changes'\n",
    "    for i, approach in enumerate(approach_map.keys(), 1):\n",
    "        data = [stars[obj][star][approach] for star in sorted_stars]\n",
    "        ax.fill_between(sorted_stars, \n",
    "                        data, \n",
    "                        label=approach_map[approach], \n",
    "                        color=color_map[approach], \n",
    "                        alpha=0.1 * i)\n",
    "\n",
    "    ax.set_title(obj.title())\n",
    "    ax.set_xlabel('Levels')\n",
    "    ax.set_ylabel('Fitness Score')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# JSON 파일 로드\n",
    "with open('data/ICL1701/feedbacks/optimal/results.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# _default 내부 데이터\n",
    "records = data['_default']\n",
    "\n",
    "# fn 그룹으로 묶기\n",
    "grouped = defaultdict(list)\n",
    "for entry in records.values():\n",
    "    for key in entry:\n",
    "        if key.startswith(\"f\"):\n",
    "            grouped[key].append({\n",
    "                \"Repair Rate\": entry[\"Repair Rate\"],\n",
    "                \"Relative Patch Size\": entry[\"Relative Patch Size\"],\n",
    "                \"AVG Time Taken(sec)\": entry[\"AVG Time Taken(sec)\"],\n",
    "            })\n",
    "\n",
    "# 평균 계산\n",
    "averages = {}\n",
    "for fn, entries in grouped.items():\n",
    "    avg_repair = sum(e[\"Repair Rate\"] for e in entries) / len(entries)\n",
    "    avg_patch_size = sum(e[\"Relative Patch Size\"] for e in entries) / len(entries)\n",
    "    avg_time = sum(e[\"AVG Time Taken(sec)\"] for e in entries) / len(entries)\n",
    "    averages[fn] = {\n",
    "        \"Repair Rate\": avg_repair,\n",
    "        \"Relative Patch Size\": avg_patch_size,\n",
    "        \"AVG Time Taken(sec)\": avg_time\n",
    "    }\n",
    "\n",
    "# 그래프 그리기\n",
    "metrics = [\"Repair Rate\", \"Relative Patch Size\", \"AVG Time Taken(sec)\"]\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(averages.keys(), [v[metric] for v in averages.values()])\n",
    "    plt.title(f'Average {metric} by fitness function')\n",
    "    plt.xlabel('fitness function')\n",
    "    plt.ylabel(metric)\n",
    "    plt.ylim(0, max(v[metric] for v in averages.values()) * 1.1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Database\n",
    "\n",
    "dataset = \"data/dataset.db\"\n",
    "dataset_db = Database(dataset)\n",
    "problem_tb = dataset_db.get_table('problem')\n",
    "experiments_tb = dataset_db.create_table('experiments')\n",
    "\n",
    "for i in range(1, 13):\n",
    "    for expeiment in experiments_tb.find(problemId=i):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('contest.json', 'r') as f:\n",
    "    contest = json.load(f)\n",
    "\n",
    "result = contest['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {i:[] for i in range(1, 6)}\n",
    "for contest in result:\n",
    "    if 'startTimeSeconds' in contest.keys() \\\n",
    "        and 'difficulty' in contest.keys():\n",
    "        if contest['startTimeSeconds'] > 1717167600:\n",
    "            data[contest['difficulty']].append(contest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Randoms\n",
    "for difficulty, contests in data.items():\n",
    "    print(f\"Difficulty {difficulty}: {len(contests)} contests\")\n",
    "    contest = Randoms.choice(contests)\n",
    "    print(contest['id'], contest['name'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/1/logs_hvpe_1.json', 'r') as f:\n",
    "    logs = json.load(f)\n",
    "\n",
    "\n",
    "for generation, results in logs.items():\n",
    "    threshold = 0\n",
    "    for b_id, solutions in results.items():\n",
    "        for p_id, scores in solutions.items():\n",
    "            scores = list(scores.values())\n",
    "            min_score = min(scores)\n",
    "            threshold = max(threshold, min_score)\n",
    "    print(f\"Generation {generation}: Threshold = {threshold}\")\n",
    "            \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Database\n",
    "\n",
    "overall = {}\n",
    "db = Database('data2/dataset.db')\n",
    "experiments = db.get_table('experiments')\n",
    "\n",
    "for exp in experiments.all():\n",
    "    problemId = exp['problemId']\n",
    "    generations = exp['generations']\n",
    "    selection = exp['selection']\n",
    "    overall.setdefault(problemId, {})\n",
    "    overall[problemId].setdefault(generations, {})\n",
    "    overall[problemId][generations].setdefault(selection, {})\n",
    "    \n",
    "    rr = exp['avg_rr']\n",
    "    rps = exp['avg_rps']\n",
    "    att = exp['avg_att']\n",
    "    f1 = exp['f1']\n",
    "    f2 = exp['f2']\n",
    "    f3 = exp['f3']\n",
    "    f4 = exp['f4']\n",
    "    f5 = exp['f5']\n",
    "    f6 = exp['f6']\n",
    "    f7 = exp['f7']\n",
    "    overall[problemId][generations][selection] = {\n",
    "        'rr': rr, 'rps': rps, 'att': att,\n",
    "        'fitness': {'f1': f1, 'f2': f2, 'f3': f3,\n",
    "        'f4': f4, 'f5': f5, 'f6': f6, 'f7': f7}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_int,max_ops=map(int,input().split())\n",
      "arr=list(map(int,input().split()))\n",
      "carry=0\n",
      "count=0\n",
      "lst_ind=[]\n",
      "ops_ind1=0\n",
      "for ops_ind2 in range(num_int):\n",
      "    val=arr[ops_ind2]\n",
      "    if val<0:\n",
      "        bit=0\n",
      "    else:\n",
      "        bit=1\n",
      "    bit_sum=bit+carry\n",
      "    if bit_sum==2 or bit_sum==0:\n",
      "        count+=1\n",
      "        carry=1\n",
      "        lst_ind.append(ops_ind2+1)\n",
      "    elif bit_sum==1:\n",
      "        carry=0\n",
      "    if count>max_ops:\n",
      "        print(-1)\n",
      "        break\n",
      "else:\n",
      "    print(count)\n",
      "    flag=0\n",
      "    for val2 in lst_ind:\n",
      "        print(val2,end=\" \")\n",
      "        flag=1\n",
      "    if flag==1:\n",
      "        print()\n",
      "{1: [], 2: [], 3: [], 4: [], 5: []}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from src.utils import TinyDatabase, DBKey, ETC, TED\n",
    "from src.execution import Tester\n",
    "from src.genetic import Fitness\n",
    "\n",
    "def ratio(numerator: float, denominator: float) -> float:\n",
    "    if numerator == 0 or denominator == 0:\n",
    "        return 0.0\n",
    "    value = ETC.divide(numerator, denominator)\n",
    "    abs_value = abs(value)\n",
    "    decimal_places = max(3, -int(math.floor(math.log10(abs_value))))\n",
    "    return round(value, decimal_places)\n",
    "\n",
    "problemId = 1\n",
    "db = TinyDatabase(f'data2/{str(problemId)}/dataset.json')\n",
    "problem = db.get_data_from_table('problem')\n",
    "title = problem['title']\n",
    "description = problem['description']\n",
    "references = db.get_data_from_table('references')\n",
    "buggys = db.get_data_from_table('buggys')\n",
    "testcases = db.table('testcases').all()\n",
    "programs = references | buggys\n",
    "Tester.init_globals(testcases, 1, 500000, title, description)\n",
    "\n",
    "for b_id, buggy in references.items():\n",
    "    results = Tester.trace(buggy)\n",
    "    test_hist = Tester.get_exec_hist(results)\n",
    "    print(test_hist)\n",
    "    break\n",
    "# fitness = Fitness()\n",
    "\n",
    "# for b_id, buggy in buggys.items():\n",
    "#     for obj in fitness.objectives:\n",
    "#         fitness.OBJ_FUNC_MAP[obj](buggy, references)\n",
    "  \n",
    "# with open('data2/1/best_solution.json', 'r') as f:\n",
    "#     solutions = json.load(f)\n",
    "\n",
    "# fixed = len(solutions)\n",
    "# tot_rps = 0\n",
    "# overall_objectives = {obj:0 for obj in Fitness.OBJECTIVES}\n",
    "# for b_id, solution in solutions.items():\n",
    "#     buggy = buggys[b_id]\n",
    "#     patch = solution['patch']\n",
    "#     scores = fitness.run(buggy, patch)\n",
    "#     # tot_rps += TED.relative_patch_size(buggy, patch)\n",
    "#     for obj in Fitness.OBJECTIVES:\n",
    "#         overall_objectives[obj] += scores[obj]\n",
    "    \n",
    "# exp = {\n",
    "#     DBKey.problemId: problemId,\n",
    "#     DBKey.title: title,\n",
    "#     DBKey.fitness: 'f1f2f3f4f5f6f7',\n",
    "#     DBKey.generations: 10,\n",
    "#     DBKey.pop_size: 10,\n",
    "#     DBKey.selection: 'Mentored',\n",
    "#     DBKey.trials: 10,\n",
    "#     DBKey.b_progs: len(buggys),\n",
    "#     DBKey.a_sol: 64,\n",
    "#     DBKey.a_rr: 0.33,\n",
    "#     DBKey.a_rps: 0.1,\n",
    "#     DBKey.a_att: 7.3,\n",
    "# }\n",
    "# exp.update(overall_objectives)\n",
    "# print(exp)\n",
    "\n",
    "# rr = exp['avg_rr']\n",
    "# rps = exp['avg_rps']\n",
    "# att = exp['avg_att']\n",
    "# f1 = exp['f1']\n",
    "# f2 = exp['f2']\n",
    "# f3 = exp['f3']\n",
    "# f4 = exp['f4']\n",
    "# f5 = exp['f5']\n",
    "# f6 = exp['f6']\n",
    "# f7 = exp['f7']\n",
    "    \n",
    "# overall[1][10]['Mentored'] = {\n",
    "#     'rr': rr, 'rps': rps, 'att': att,\n",
    "#     'fitness': {'f1': f1, 'f2': f2, 'f3': f3,\n",
    "#     'f4': f4, 'f5': f5, 'f6': f6, 'f7': f7}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "TARGET_GENERATION = 10\n",
    "methods = ['Refactory', 'Mentored', 'MooRepair']\n",
    "\n",
    "# 데이터 전처리\n",
    "problemIds = sorted(overall.keys())\n",
    "num_problems = len(problemIds)\n",
    "\n",
    "# subplot 설정 (2행 4열)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 각 problemId별 subplot 생성\n",
    "for i, problemId in enumerate(problemIds):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # TARGET_GENERATION이 해당 problemId에 존재하는지 확인\n",
    "    if TARGET_GENERATION not in overall[problemId]:\n",
    "        ax.set_title(f'Problem {problemId} (No data for gen {TARGET_GENERATION})')\n",
    "        ax.text(0.5, 0.5, f'No data for\\ngeneration {TARGET_GENERATION}', \n",
    "                ha='center', va='center', transform=ax.transAxes)\n",
    "        continue\n",
    "    \n",
    "    # 각 selection별로 선 그리기\n",
    "    for j, selection in enumerate(methods):\n",
    "        if selection not in overall[problemId][TARGET_GENERATION]:\n",
    "            continue\n",
    "        fitness_data = overall[problemId][TARGET_GENERATION][selection]['fitness']\n",
    "        fitness_values = [\n",
    "            fitness_data['f1'], fitness_data['f2'], fitness_data['f3'],\n",
    "            fitness_data['f4'], fitness_data['f5'], fitness_data['f6'],\n",
    "            fitness_data['f7']\n",
    "        ]\n",
    "        \n",
    "        # 선 그리기\n",
    "        x_labels = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7']\n",
    "        ax.plot(x_labels, fitness_values, marker='o', label=selection, alpha=0.4)\n",
    "    \n",
    "    ax.set_title(f'Problem {problemId} (Gen {TARGET_GENERATION})')\n",
    "    ax.set_xlabel('Objective Functions')\n",
    "    ax.set_ylabel('Fitness Value')\n",
    "    ax.legend()\n",
    "\n",
    "# 마지막 subplot에 전체 평균 그리기\n",
    "if num_problems < len(axes):\n",
    "    ax = axes[num_problems]\n",
    "    \n",
    "    # 모든 problemId에서 TARGET_GENERATION의 selection별 평균 계산\n",
    "    selection_averages = defaultdict(list)\n",
    "    \n",
    "    for problemId in problemIds:\n",
    "        if TARGET_GENERATION in overall[problemId]:\n",
    "            for selection in methods:\n",
    "                fitness_data = overall[problemId][TARGET_GENERATION][selection]['fitness']\n",
    "                fitness_values = [\n",
    "                    fitness_data['f1'], fitness_data['f2'], fitness_data['f3'],\n",
    "                    fitness_data['f4'], fitness_data['f5'], fitness_data['f6'],\n",
    "                    fitness_data['f7']\n",
    "                ]\n",
    "                selection_averages[selection].append(fitness_values)\n",
    "    \n",
    "    # 각 selection별 전체 평균 계산 및 그리기\n",
    "    x_labels = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7']\n",
    "    for j, (selection, values) in enumerate(selection_averages.items()):\n",
    "        if values:  # 데이터가 있는 경우에만\n",
    "            overall_avg = np.mean(values, axis=0)\n",
    "            ax.plot(x_labels, overall_avg, marker='o', label=selection, alpha=0.4)\n",
    "    \n",
    "    ax.set_xlabel('Objective Functions')\n",
    "    ax.set_ylabel('Fitness Value')\n",
    "    ax.legend()\n",
    "\n",
    "# 사용하지 않는 subplot 숨기기\n",
    "for i in range(num_problems + 1, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycparser in ./env/lib/python3.10/site-packages (2.23)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pycparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code1 nesting depth: 2\n",
      "Code2 nesting depth: 3\n"
     ]
    }
   ],
   "source": [
    "from pycparser import c_parser, c_ast, parse_file\n",
    "import pycparser\n",
    "\n",
    "class LoopNestingVisitor(c_ast.NodeVisitor):\n",
    "    \"\"\"AST를 방문하며 루프 중첩 깊이를 계산\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.max_nesting = 0\n",
    "        self.current_nesting = 0\n",
    "    \n",
    "    def visit_For(self, node):\n",
    "        \"\"\"For 루프 방문\"\"\"\n",
    "        self.current_nesting += 1\n",
    "        self.max_nesting = max(self.max_nesting, self.current_nesting)\n",
    "        # 자식 노드 방문\n",
    "        self.generic_visit(node)\n",
    "        self.current_nesting -= 1\n",
    "    \n",
    "    def visit_While(self, node):\n",
    "        \"\"\"While 루프 방문\"\"\"\n",
    "        self.current_nesting += 1\n",
    "        self.max_nesting = max(self.max_nesting, self.current_nesting)\n",
    "        self.generic_visit(node)\n",
    "        self.current_nesting -= 1\n",
    "    \n",
    "    def visit_DoWhile(self, node):\n",
    "        \"\"\"Do-While 루프 방문\"\"\"\n",
    "        self.current_nesting += 1\n",
    "        self.max_nesting = max(self.max_nesting, self.current_nesting)\n",
    "        self.generic_visit(node)\n",
    "        self.current_nesting -= 1\n",
    "\n",
    "def count_loop_nesting(c_code):\n",
    "    \"\"\"\n",
    "    C 코드의 최대 루프 중첩 깊이를 계산\n",
    "    \n",
    "    Args:\n",
    "        c_code: C 소스 코드 문자열\n",
    "    \n",
    "    Returns:\n",
    "        int: 최대 루프 중첩 깊이\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # pycparser는 전처리된 코드가 필요하므로 간단한 전처리\n",
    "        # 실제로는 fake_libc_include를 사용하거나 전처리 필요\n",
    "        parser = c_parser.CParser()\n",
    "        \n",
    "        # 간단한 wrapper 추가 (함수가 아닌 경우)\n",
    "        if 'int main' not in c_code and 'void ' not in c_code:\n",
    "            c_code = f\"void temp_func() {{ {c_code} }}\"\n",
    "        \n",
    "        ast = parser.parse(c_code)\n",
    "        \n",
    "        visitor = LoopNestingVisitor()\n",
    "        visitor.visit(ast)\n",
    "        \n",
    "        return visitor.max_nesting\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error: {e}\")\n",
    "        return 0\n",
    "\n",
    "# 사용 예시\n",
    "c_code1 = \"\"\"\n",
    "int main() {\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        for (int j = 0; j < 10; j++) {\n",
    "            printf(\"%d\", i + j);\n",
    "        }\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "c_code2 = \"\"\"\n",
    "int main() {\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        for (int j = 0; j < 10; j++) {\n",
    "            for (int k = 0; k < 10; k++) {\n",
    "                printf(\"%d\", i + j + k);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Code1 nesting depth: {count_loop_nesting(c_code1)}\")  # 2\n",
    "print(f\"Code2 nesting depth: {count_loop_nesting(c_code2)}\")  # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import Loader\n",
    "\n",
    "dataset_path = 'data/problemID_2/dataset.json'\n",
    "loader = Loader()\n",
    "problemId, description, buggys, references, testcases = loader.run(dataset_path)\n",
    "prompts = f\"\"\"{description}\n",
    "\n",
    "[reference code]\n",
    "{references[0].code}\n",
    "[buggy code]\n",
    "{buggys[0].code}\n",
    "\n",
    "please fix the buggy code and return the correct code.\n",
    "\"\"\"\n",
    "\n",
    "# print(prompts)\n",
    "# print(testcases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207fb759c7264618b7f159258317d225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min tokens: 1065\n",
      "Average tokens: 1383.2032520325204\n",
      "Max tokens: 2647\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from src.genetic import Fitness\n",
    "from src.execution import Tester\n",
    "from src.llms import Ollama\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SYSTEM_PROMPT = '''# Role\n",
    "\n",
    "You are an expert {language} programming tutor who helps to fix buggy program.\n",
    "\n",
    "# Task\n",
    "\n",
    "You will be given a 'Problem Description', a set of 'Test Cases', a 'Buggy Program', a 'Reference Program' and their test results as Inputs.\n",
    "Generate the 'Fixed Program' by repairing the 'Buggy Program' according to the following priority guidelines:\n",
    "{guidelines}\n",
    "\n",
    "Outputs should be a 'Fixed Program' as str.\n",
    "'''\n",
    "\n",
    "USER_PROMPT = \"\"\"# Inputs\n",
    "\n",
    "## Problem Description\n",
    "{description}\n",
    "\n",
    "## Buggy Program\n",
    "{buggy_program}\n",
    "### Buggy Test Results\n",
    "{buggy_results}\n",
    "\n",
    "## Reference Program\n",
    "{reference_program}\n",
    "### Reference Test Results\n",
    "{reference_results}\n",
    "\"\"\"\n",
    "\n",
    "ollama = Ollama()\n",
    "fitness = Fitness()\n",
    "Tester.init_globals(testcases, timelimit=1)\n",
    "guidelines = fitness.guidelines.values()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\", use_fast=False)\n",
    "\n",
    "class OutFormat(BaseModel):\n",
    "    fixed_program: str\n",
    "\n",
    "def post_process(text: str) -> str | None:\n",
    "    if text.startswith(\"```\") and text.endswith(\"```\"):\n",
    "        m = re.search(r\"```(?:[a-zA-Z0-9_+-]+)?\\n(.*?)```\", text, flags=re.DOTALL)\n",
    "        return m.group(1).strip() if m else None\n",
    "    return text.strip()\n",
    "\n",
    "avg_tokens = []\n",
    "out_tokens = []\n",
    "fixed_programs = []\n",
    "for buggy in tqdm(buggys):\n",
    "    refer = references.get_prog_by_id(buggy.id)\n",
    "    \n",
    "    b_results = Tester.run(buggy)\n",
    "    b_passed, b_failed = Tester.tests_split(b_results)\n",
    "    buggy_results = f\"Passed Test Cases IDs: {sorted([tc.id for tc in b_passed])}  \\n\"\n",
    "    buggy_results += f\"Failed Test Cases IDs: {sorted([tc.id for tc in b_failed])}\\n\"     \n",
    "    \n",
    "    r_results = Tester.run(refer)\n",
    "    r_passed, r_failed = Tester.tests_split(r_results)\n",
    "    reference_results = f\"Passed Test Cases IDs: {sorted([tc.id for tc in r_passed])}  \\n\"\n",
    "    reference_results += f\"Failed Test Cases IDs: {sorted([tc.id for tc in r_failed])}\\n\"\n",
    "    \n",
    "    # System Prompt\n",
    "    system = SYSTEM_PROMPT.format(\n",
    "        language=buggy.ext,\n",
    "        guidelines=guidelines\n",
    "    )\n",
    "    \n",
    "    # User Prompt\n",
    "    user = USER_PROMPT.format(\n",
    "        description=description,\n",
    "        buggy_program=f\"```{buggy.ext}\\n{buggy.code}\\n```\",\n",
    "        buggy_results=buggy_results,\n",
    "        reference_program=f\"```{refer.ext}\\n{refer.code}\\n```\",\n",
    "        reference_results=reference_results,\n",
    "    )\n",
    "    \n",
    "    prompt = system + \"\\n\" + user\n",
    "    tokens = tokenizer.tokenize(prompt)\n",
    "    avg_tokens.append(len(tokens))\n",
    "    \n",
    "    # response = await ollama.run(system=system, user=user, format=OutFormat)\n",
    "    # if response is not None:\n",
    "    #     fixed_program = post_process(response.fixed_program)\n",
    "    #     out_tok = tokenizer.tokenize(fixed_program)\n",
    "    #     fixed_programs.append(fixed_program)\n",
    "    # else:\n",
    "    #     out_tok = []\n",
    "    # out_tokens.append(len(out_tok))\n",
    "\n",
    "print(\"Min tokens:\", min(avg_tokens))\n",
    "print(\"Average tokens:\", sum(avg_tokens) / len(references))\n",
    "print(\"Max tokens:\", max(avg_tokens))\n",
    "\n",
    "# print(\"Min output tokens:\", min(out_tokens))\n",
    "# print(\"Average output tokens:\", sum(out_tokens) / len(references))\n",
    "# print(\"Max output tokens:\", max(out_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
